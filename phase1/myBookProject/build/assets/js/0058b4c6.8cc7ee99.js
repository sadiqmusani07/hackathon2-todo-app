"use strict";(self.webpackChunkmybookproject=self.webpackChunkmybookproject||[]).push([[849],{6164(e){e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/docs/intro","label":"Introduction","docId":"intro","unlisted":false},{"type":"category","label":"Module 1: ROS 2 Nervous System","items":[{"type":"link","href":"/docs/module-1/ros2-fundamentals","label":"Module 1, Chapter 1: ROS 2 Core Concepts - Nodes, Topics, and Services","docId":"module-1/ros2-fundamentals","unlisted":false},{"type":"link","href":"/docs/module-1/python-ai-integration","label":"Module 1, Chapter 2: Python AI Agents with rclpy","docId":"module-1/python-ai-integration","unlisted":false},{"type":"link","href":"/docs/module-1/urdf-modeling","label":"Module 1, Chapter 3: Humanoid Modeling with URDF","docId":"module-1/urdf-modeling","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Digital Twin (Gazebo & Unity)","items":[{"type":"link","href":"/docs/module-2/physics-simulation-gazebo","label":"Chapter 1: Physics Simulation in Gazebo","docId":"module-2/physics-simulation-gazebo","unlisted":false},{"type":"link","href":"/docs/module-2/high-fidelity-rendering-unity","label":"Chapter 2: High-Fidelity Rendering in Unity","docId":"module-2/high-fidelity-rendering-unity","unlisted":false},{"type":"link","href":"/docs/module-2/sensor-environment-integration","label":"Chapter 3: Sensor and Environment Integration","docId":"module-2/sensor-environment-integration","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: AI-Robot Brain (NVIDIA Isaac\u2122)","items":[{"type":"link","href":"/docs/module-3/isaac-sim-overview","label":"Module 3, Chapter 1: NVIDIA Isaac Sim Overview","docId":"module-3/isaac-sim-overview","unlisted":false},{"type":"link","href":"/docs/module-3/isaac-ros-perception-navigation","label":"Module 3, Chapter 2: Isaac ROS for Perception and Navigation","docId":"module-3/isaac-ros-perception-navigation","unlisted":false},{"type":"link","href":"/docs/module-3/nav2-path-planning","label":"Module 3, Chapter 3: Path Planning with Nav2","docId":"module-3/nav2-path-planning","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"link","href":"/docs/module-4/voice-to-action","label":"Module 4, Chapter 1: Voice-to-Action with Speech Recognition","docId":"module-4/voice-to-action","unlisted":false},{"type":"link","href":"/docs/module-4/llm-cognitive-planning","label":"Module 4, Chapter 2: Cognitive Planning with Large Language Models","docId":"module-4/llm-cognitive-planning","unlisted":false},{"type":"link","href":"/docs/module-4/autonomous-humanoid","label":"Module 4, Chapter 3: Capstone - The Autonomous Humanoid","docId":"module-4/autonomous-humanoid","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","href":"/docs/glossary","label":"Glossary","docId":"glossary","unlisted":false},{"type":"link","href":"/docs/conclusion","label":"Conclusion","docId":"conclusion","unlisted":false}]},"docs":{"conclusion":{"id":"conclusion","title":"Conclusion","description":"Congratulations on completing the ROS 2 Nervous System for Physical AI & Humanoid Robotics course! You now have a solid foundation in:","sidebar":"tutorialSidebar"},"glossary":{"id":"glossary","title":"Glossary","description":"This glossary contains key terms and definitions used throughout the ROS 2 Nervous System for Physical AI & Humanoid Robotics course.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Introduction","description":"ROS 2 Architecture","sidebar":"tutorialSidebar"},"module-1/python-ai-integration":{"id":"module-1/python-ai-integration","title":"Module 1, Chapter 2: Python AI Agents with rclpy","description":"Connect AI agents to robotic systems using Python and rclpy","sidebar":"tutorialSidebar"},"module-1/ros2-fundamentals":{"id":"module-1/ros2-fundamentals","title":"Module 1, Chapter 1: ROS 2 Core Concepts - Nodes, Topics, and Services","description":"Learn about ROS 2 as robotic middleware, nodes, topics, and services","sidebar":"tutorialSidebar"},"module-1/urdf-modeling":{"id":"module-1/urdf-modeling","title":"Module 1, Chapter 3: Humanoid Modeling with URDF","description":"Define robot bodies for humanoid robotics using URDF","sidebar":"tutorialSidebar"},"module-2/high-fidelity-rendering-unity":{"id":"module-2/high-fidelity-rendering-unity","title":"Chapter 2: High-Fidelity Rendering in Unity","description":"Learn to create realistic visualizations in Unity for digital twin applications","sidebar":"tutorialSidebar"},"module-2/physics-simulation-gazebo":{"id":"module-2/physics-simulation-gazebo","title":"Chapter 1: Physics Simulation in Gazebo","description":"Learn to create realistic physics simulations in Gazebo for humanoid robotics","sidebar":"tutorialSidebar"},"module-2/sensor-environment-integration":{"id":"module-2/sensor-environment-integration","title":"Chapter 3: Sensor and Environment Integration","description":"Learn to connect simulated sensors to ROS 2 nodes and create complete digital twin systems","sidebar":"tutorialSidebar"},"module-3/isaac-ros-perception-navigation":{"id":"module-3/isaac-ros-perception-navigation","title":"Module 3, Chapter 2: Isaac ROS for Perception and Navigation","description":"Learn to implement perception and navigation using Isaac ROS nodes and pipelines with hardware-accelerated VSLAM","sidebar":"tutorialSidebar"},"module-3/isaac-sim-overview":{"id":"module-3/isaac-sim-overview","title":"Module 3, Chapter 1: NVIDIA Isaac Sim Overview","description":"Learn to configure NVIDIA Isaac Sim for humanoid robot simulation with photorealistic rendering and synthetic data generation","sidebar":"tutorialSidebar"},"module-3/nav2-path-planning":{"id":"module-3/nav2-path-planning","title":"Module 3, Chapter 3: Path Planning with Nav2","description":"Learn to implement path planning using Nav2 specifically adapted for bipedal humanoid movement patterns and constraints","sidebar":"tutorialSidebar"},"module-4/autonomous-humanoid":{"id":"module-4/autonomous-humanoid","title":"Module 4, Chapter 3: Capstone - The Autonomous Humanoid","description":"Build complete end-to-end VLA system with voice command to action execution, coordinated with ROS 2 for humanoid robot autonomy","sidebar":"tutorialSidebar"},"module-4/llm-cognitive-planning":{"id":"module-4/llm-cognitive-planning","title":"Module 4, Chapter 2: Cognitive Planning with Large Language Models","description":"Learn to implement cognitive planning using LLMs to translate natural language goals into action plans for humanoid robots","sidebar":"tutorialSidebar"},"module-4/voice-to-action":{"id":"module-4/voice-to-action","title":"Module 4, Chapter 1: Voice-to-Action with Speech Recognition","description":"Learn to integrate speech recognition with humanoid robots using OpenAI Whisper and ROS 2 messaging","sidebar":"tutorialSidebar"}}}}')}}]);