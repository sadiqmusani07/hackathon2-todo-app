"use strict";(self.webpackChunkmybookproject=self.webpackChunkmybookproject||[]).push([[3025],{5263(e,n,i){i.d(n,{A:()=>t});const t="data:image/jpeg;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI4MDAiIGhlaWdodD0iNDAwIiB2aWV3Qm94PSIwIDAgODAwIDQwMCI+CiAgPHJlY3Qgd2lkdGg9IjgwMCIgaGVpZ2h0PSI0MDAiIGZpbGw9IiNmMGY4ZmYiLz4KICA8cmVjdCB4PSIzMDAiIHk9IjEwMCIgd2lkdGg9IjIwMCIgaGVpZ2h0PSIyMDAiIGZpbGw9IiM0NjgyYjQiIHN0cm9rZT0iIzAwMCIgc3Ryb2tlLXdpZHRoPSIyIi8+CiAgPGNpcmNsZSBjeD0iMzUwIiBjeT0iMTUwIiByPSIyMCIgZmlsbD0iI2ZmZiIgc3Ryb2tlPSIjMDAwIiBzdHJva2Utd2lkdGg9IjIiLz4KICA8Y2lyY2xlIGN4PSI0NTAiIGN5PSIxNTAiIHI9IjIwIiBmaWxsPSIjZmZmIiBzdHJva2U9IiMwMDAiIHN0cm9rZS13aWR0aD0iMiIvPgogIDxyZWN0IHg9IjMyNSIgeT0iMjIwIiB3aWR0aD0iMTUwIiBoZWlnaHQ9IjUwIiBmaWxsPSIjNTU2YjJmIiBzdHJva2U9IiMwMDAiIHN0cm9rZS13aWR0aD0iMiIvPgogIDx0ZXh0IHg9IjQwMCIgeT0iMzIwIiBmb250LWZhbWlseT0iQXJpYWwiIGZvbnQtc2l6ZT0iMjQiIGZpbGw9IiMzMzMiIHRleHQtYW5jaG9yPSJtaWRkbGUiPlJPUyAyIFJvYm90PC90ZXh0Pgo8L3N2Zz4="},6064(e,n,i){i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-3/isaac-sim-overview","title":"Module 3, Chapter 1: NVIDIA Isaac Sim Overview","description":"Learn to configure NVIDIA Isaac Sim for humanoid robot simulation with photorealistic rendering and synthetic data generation","source":"@site/docs/module-3/01-isaac-sim-overview.md","sourceDirName":"module-3","slug":"/module-3/isaac-sim-overview","permalink":"/docs/module-3/isaac-sim-overview","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Module 3, Chapter 1: NVIDIA Isaac Sim Overview","description":"Learn to configure NVIDIA Isaac Sim for humanoid robot simulation with photorealistic rendering and synthetic data generation"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Sensor and Environment Integration","permalink":"/docs/module-2/sensor-environment-integration"},"next":{"title":"Module 3, Chapter 2: Isaac ROS for Perception and Navigation","permalink":"/docs/module-3/isaac-ros-perception-navigation"}}');var a=i(4848),r=i(8453);const o={sidebar_position:1,title:"Module 3, Chapter 1: NVIDIA Isaac Sim Overview",description:"Learn to configure NVIDIA Isaac Sim for humanoid robot simulation with photorealistic rendering and synthetic data generation"},s="Module 3, Chapter 1: NVIDIA Isaac Sim Overview",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Setting Up NVIDIA Isaac Sim for Photorealistic Rendering",id:"setting-up-nvidia-isaac-sim-for-photorealistic-rendering",level:2},{value:"Installing Isaac Sim",id:"installing-isaac-sim",level:3},{value:"Basic Photorealistic Rendering Configuration",id:"basic-photorealistic-rendering-configuration",level:3},{value:"Creating Your First Photorealistic World",id:"creating-your-first-photorealistic-world",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"Understanding Synthetic Data",id:"understanding-synthetic-data",level:3},{value:"Configuring Synthetic Data Pipelines",id:"configuring-synthetic-data-pipelines",level:3},{value:"Robot Model Import and Environment Configuration",id:"robot-model-import-and-environment-configuration",level:2},{value:"Importing Robot Models",id:"importing-robot-models",level:3},{value:"Environment Setup",id:"environment-setup",level:3},{value:"Sensor Simulation (RGB, Depth, LiDAR)",id:"sensor-simulation-rgb-depth-lidar",level:2},{value:"RGB Camera Simulation",id:"rgb-camera-simulation",level:3},{value:"Depth Camera Simulation",id:"depth-camera-simulation",level:3},{value:"LiDAR Simulation",id:"lidar-simulation",level:3},{value:"Scene Optimization for AI Perception",id:"scene-optimization-for-ai-perception",level:2},{value:"Performance Optimization Techniques",id:"performance-optimization-techniques",level:3},{value:"Optimizing for Training Efficiency",id:"optimizing-for-training-efficiency",level:3},{value:"Multi-View Scene Generation",id:"multi-view-scene-generation",level:3},{value:"Practical Exercise: Creating a Complete Scene",id:"practical-exercise-creating-a-complete-scene",level:2},{value:"Summary",id:"summary",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"module-3-chapter-1-nvidia-isaac-sim-overview",children:"Module 3, Chapter 1: NVIDIA Isaac Sim Overview"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Isaac Sim Overview",src:i(5263).A+"",width:"800",height:"400"})}),"\n",(0,a.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(n.p,{children:"NVIDIA Isaac Sim is a powerful simulation environment that provides photorealistic rendering and synthetic data generation capabilities for robotics development. In this chapter, you'll learn how to set up Isaac Sim for humanoid robot simulation, import robot models, configure environments, and simulate various sensors."}),"\n",(0,a.jsx)(n.h2,{id:"setting-up-nvidia-isaac-sim-for-photorealistic-rendering",children:"Setting Up NVIDIA Isaac Sim for Photorealistic Rendering"}),"\n",(0,a.jsx)(n.h3,{id:"installing-isaac-sim",children:"Installing Isaac Sim"}),"\n",(0,a.jsx)(n.p,{children:"Before we begin, ensure you have Isaac Sim installed. For the best experience with humanoid robotics, we recommend Isaac Sim 2023.1 or later:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# For Omniverse users\n# Download Isaac Sim from NVIDIA Developer Zone\n# Or install via Omniverse Launcher\n\n# Verify installation\nisaac-sim --version\n"})}),"\n",(0,a.jsx)(n.h3,{id:"basic-photorealistic-rendering-configuration",children:"Basic Photorealistic Rendering Configuration"}),"\n",(0,a.jsx)(n.p,{children:"Isaac Sim provides advanced rendering capabilities using RTX technology. The core rendering parameters include:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Physically-Based Rendering (PBR)"}),": Simulates real-world lighting and materials"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Ray Tracing"}),": Enables realistic reflections and shadows"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Global Illumination"}),": Simulates indirect lighting effects"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Synthetic Data Generation"}),": Creates labeled training data for AI models"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"creating-your-first-photorealistic-world",children:"Creating Your First Photorealistic World"}),"\n",(0,a.jsx)(n.p,{children:"Let's start by creating a basic world file with photorealistic rendering:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example: Basic Isaac Sim scene setup\nimport omni\nimport carb\nfrom pxr import Gf, Sdf, UsdGeom\n\n# Initialize Isaac Sim\nomni.kit.commands.execute("ChangeStageMetersPerUnit", meters_per_unit=0.01)\n\n# Create a basic scene\nstage = omni.usd.get_context().get_stage()\ndefault_prim = stage.GetDefaultPrim()\nif not default_prim:\n    default_prim = stage.DefinePrim("/World", "Xform")\n\n# Add lighting\ndome_light = UsdGeom.DomeLight.Define(stage, "/World/DomeLight")\ndome_light.CreateIntensityAttr(500)\ndome_light.CreateTextureFileAttr("path/to/sky_hdri.exr")\n\n# Add environment\nground_plane = UsdGeom.Xform.Define(stage, "/World/GroundPlane")\n# Add ground plane with realistic materials\n'})}),"\n",(0,a.jsx)(n.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,a.jsx)(n.h3,{id:"understanding-synthetic-data",children:"Understanding Synthetic Data"}),"\n",(0,a.jsx)(n.p,{children:"Synthetic data generation is a key feature of Isaac Sim that allows you to create large amounts of labeled training data for AI models:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"RGB Images"}),": Color images with realistic lighting"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Depth Maps"}),": Per-pixel depth information"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Semantic Segmentation"}),": Pixel-level object classification"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Instance Segmentation"}),": Pixel-level instance identification"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Bounding Boxes"}),": 2D and 3D bounding boxes for objects"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Pose Labels"}),": 6D pose estimation for objects"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"configuring-synthetic-data-pipelines",children:"Configuring Synthetic Data Pipelines"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example: Setting up synthetic data generation\nfrom omni.isaac.synthetic_utils import SyntheticDataHelper\n\n# Initialize synthetic data helper\nsynth_helper = SyntheticDataHelper()\n\n# Configure RGB camera\nrgb_camera = synth_helper.add_rgb_camera(\n    prim_path="/World/Robot/Camera",\n    resolution=(640, 480),\n    frequency=30  # Hz\n)\n\n# Configure depth camera\ndepth_camera = synth_helper.add_depth_camera(\n    prim_path="/World/Robot/DepthCamera",\n    resolution=(640, 480),\n    frequency=30\n)\n\n# Configure semantic segmentation\nsemantic_camera = synth_helper.add_semantic_camera(\n    prim_path="/World/Robot/SemanticCamera",\n    resolution=(640, 480),\n    frequency=30\n)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"robot-model-import-and-environment-configuration",children:"Robot Model Import and Environment Configuration"}),"\n",(0,a.jsx)(n.h3,{id:"importing-robot-models",children:"Importing Robot Models"}),"\n",(0,a.jsx)(n.p,{children:"Isaac Sim supports various robot model formats, but the most common is USD (Universal Scene Description):"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example: Importing a humanoid robot model\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\n\n# Import humanoid robot from Isaac Sim assets\nassets_root_path = get_assets_root_path()\nif assets_root_path is None:\n    carb.log_error("Could not find Isaac Sim assets. Please enable Isaac Sim Nucleus.")\n\n# Add humanoid robot to stage\nrobot_path = assets_root_path + "/Isaac/Robots/Humanoid/humanoid_instanceable.usd"\nadd_reference_to_stage(usd_path=robot_path, prim_path="/World/HumanoidRobot")\n\n# Set initial position\nfrom omni.isaac.core.utils.transformations import set_local_pose\nset_local_pose("/World/HumanoidRobot", position=(0, 0, 1.0), orientation=(1, 0, 0, 0))\n'})}),"\n",(0,a.jsx)(n.h3,{id:"environment-setup",children:"Environment Setup"}),"\n",(0,a.jsx)(n.p,{children:"Creating realistic environments is crucial for effective training:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example: Setting up a realistic indoor environment\nfrom omni.isaac.core.utils.prims import create_primitive\n\n# Create walls\nwall_1 = create_primitive(\n    prim_path="/World/Wall1",\n    primitive_type="Cube",\n    scale=(10, 0.2, 3),\n    position=(0, -5, 1.5),\n    orientation=(0, 0, 0, 1)\n)\n\n# Create obstacles\nobstacle_1 = create_primitive(\n    prim_path="/World/Obstacle1",\n    primitive_type="Cylinder",\n    scale=(0.5, 0.5, 1),\n    position=(2, 0, 0.5),\n    orientation=(0, 0, 0, 1)\n)\n\n# Add realistic materials\nfrom omni.isaac.core.materials import PhysicsMaterial\nfloor_material = PhysicsMaterial(\n    prim_path="/World/Materials/FloorMaterial",\n    static_friction=0.5,\n    dynamic_friction=0.5,\n    restitution=0.1\n)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"sensor-simulation-rgb-depth-lidar",children:"Sensor Simulation (RGB, Depth, LiDAR)"}),"\n",(0,a.jsx)(n.h3,{id:"rgb-camera-simulation",children:"RGB Camera Simulation"}),"\n",(0,a.jsx)(n.p,{children:"RGB cameras in Isaac Sim provide realistic color images:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example: Setting up RGB camera\nfrom omni.isaac.sensor import Camera\n\n# Create camera\nrgb_cam = Camera(\n    prim_path="/World/HumanoidRobot/RGB_Camera",\n    frequency=30,\n    resolution=(640, 480),\n    position=(0.1, 0, 0.1),\n    orientation=(0, 0, 0, 1)\n)\n\n# Get RGB data\nrgb_data = rgb_cam.get_rgb()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"depth-camera-simulation",children:"Depth Camera Simulation"}),"\n",(0,a.jsx)(n.p,{children:"Depth cameras provide per-pixel distance information:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example: Setting up depth camera\nfrom omni.isaac.sensor import Camera\n\n# Create depth camera\ndepth_cam = Camera(\n    prim_path="/World/HumanoidRobot/Depth_Camera",\n    frequency=30,\n    resolution=(640, 480),\n    position=(0.1, 0, 0.1),\n    orientation=(0, 0, 0, 1)\n)\n\n# Get depth data\ndepth_data = depth_cam.get_depth()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"lidar-simulation",children:"LiDAR Simulation"}),"\n",(0,a.jsx)(n.p,{children:"LiDAR sensors simulate laser scanning for 3D mapping:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example: Setting up LiDAR sensor\nfrom omni.isaac.range_sensor import _range_sensor\nimport omni.isaac.core.utils.numpy.rotations as rot_utils\n\n# Create LiDAR sensor\nlidar_interface = _range_sensor.acquire_lidar_sensor_interface()\nlidar_path = "/World/HumanoidRobot/LiDAR_Sensor"\n\n# Configure LiDAR parameters\nlidar_config = {\n    "rotation_frequency": 20,\n    "samples_per_scan": 1080,\n    "max_range": 25.0,\n    "min_range": 0.1,\n    "angles": {"start_angle": -90, "end_angle": 90},\n    "lasers": {"yaw_offset": 0, "current_distance": 0}\n}\n\n# Create LiDAR prim\nlidar_interface.create_lidar_sensor(\n    world._world_ptr,\n    lidar_path,\n    translation=(0.1, 0, 0.1),\n    orientation=rot_utils.gf_quat_to_np_array(Gf.Quatd(1, 0, 0, 0)),\n    config=lidar_config\n)\n\n# Get LiDAR data\nlidar_data = lidar_interface.get_linear_depth_data(world._world_ptr, lidar_path)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"scene-optimization-for-ai-perception",children:"Scene Optimization for AI Perception"}),"\n",(0,a.jsx)(n.h3,{id:"performance-optimization-techniques",children:"Performance Optimization Techniques"}),"\n",(0,a.jsx)(n.p,{children:"For effective AI perception training, optimize your scenes:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"LOD (Level of Detail)"}),": Use simpler models when far from camera"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Occlusion Culling"}),": Don't render objects not visible to sensors"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Texture Streaming"}),": Load textures on demand"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Light Culling"}),": Limit lighting calculations to visible areas"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"optimizing-for-training-efficiency",children:"Optimizing for Training Efficiency"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example: Scene optimization settings\ncarb.settings.get_settings().set("/app/renderer/antiAliasing", 2)  # FXAA\ncarb.settings.get_settings().set("/app/renderer/ambientLightStrength", 0.1)\ncarb.settings.get_settings().set("/app/renderer/reflections", True)\ncarb.settings.get_settings().set("/app/renderer/shadows", True)\n\n# Limit physics updates for static scenes\ncarb.settings.get_settings().set("/physics_solver_max_position_iterations", 4)\ncarb.settings.get_settings().set("/physics_solver_max_velocity_iterations", 1)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"multi-view-scene-generation",children:"Multi-View Scene Generation"}),"\n",(0,a.jsx)(n.p,{children:"Create diverse training scenarios:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example: Generating multiple scene variations\nimport random\n\ndef generate_random_scene():\n    # Random lighting conditions\n    dome_light.GetIntensityAttr().Set(random.uniform(100, 1000))\n\n    # Random object positions\n    for i in range(5):\n        pos_x = random.uniform(-3, 3)\n        pos_y = random.uniform(-3, 3)\n        set_local_pose(f"/World/RandomObject{i}", position=(pos_x, pos_y, 0.5))\n\n    # Random weather conditions\n    # (Requires additional assets and configuration)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"practical-exercise-creating-a-complete-scene",children:"Practical Exercise: Creating a Complete Scene"}),"\n",(0,a.jsx)(n.p,{children:"Let's create a complete scene that demonstrates all concepts:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Complete example: Humanoid robot in indoor environment with sensors\nimport omni\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\nfrom omni.isaac.core.utils.prims import create_primitive\nfrom omni.isaac.sensor import Camera\nfrom omni.isaac.synthetic_utils import SyntheticDataHelper\nimport carb\n\n# Initialize world\nworld = World(stage_units_in_meters=1.0)\n\n# Get Isaac Sim assets\nassets_root_path = get_assets_root_path()\nif assets_root_path is None:\n    carb.log_error("Could not find Isaac Sim assets")\n\n# Add humanoid robot\nrobot_path = assets_root_path + "/Isaac/Robots/Humanoid/humanoid_instanceable.usd"\nadd_reference_to_stage(usd_path=robot_path, prim_path="/World/HumanoidRobot")\n\n# Create environment\ncreate_primitive(\n    prim_path="/World/GroundPlane",\n    primitive_type="Plane",\n    scale=(10, 10, 1),\n    position=(0, 0, 0),\n    orientation=(0, 0, 0, 1)\n)\n\n# Add obstacles\nfor i, pos in enumerate([(2, 1, 0.5), (-2, -1, 0.5), (0, 2, 0.5)]):\n    create_primitive(\n        prim_path=f"/World/Obstacle{i}",\n        primitive_type="Box",\n        scale=(0.5, 0.5, 1),\n        position=pos,\n        orientation=(0, 0, 0, 1)\n    )\n\n# Add sensors to robot\nrgb_camera = Camera(\n    prim_path="/World/HumanoidRobot/Head/RGB_Camera",\n    frequency=30,\n    resolution=(640, 480),\n    position=(0.1, 0, 0.1)\n)\n\ndepth_camera = Camera(\n    prim_path="/World/HumanoidRobot/Head/Depth_Camera",\n    frequency=30,\n    resolution=(640, 480),\n    position=(0.1, 0, 0.1)\n)\n\n# Configure synthetic data\nsynth_helper = SyntheticDataHelper()\nsynth_helper.add_rgb_camera("/World/HumanoidRobot/Head/RGB_Camera", (640, 480), 30)\n\n# Play the world\nworld.reset()\nfor i in range(100):\n    world.step(render=True)\n\n    # Get sensor data\n    rgb_image = rgb_camera.get_rgb()\n    depth_image = depth_camera.get_depth()\n\n    # Process data for AI training\n    if i % 30 == 0:  # Every second\n        print(f"Captured RGB frame {i//30}")\n\nworld.stop()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"In this chapter, you've learned how to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Set up NVIDIA Isaac Sim with photorealistic rendering capabilities"}),"\n",(0,a.jsx)(n.li,{children:"Configure synthetic data generation pipelines for AI training"}),"\n",(0,a.jsx)(n.li,{children:"Import humanoid robot models and configure environments"}),"\n",(0,a.jsx)(n.li,{children:"Simulate various sensors (RGB, Depth, LiDAR) with realistic parameters"}),"\n",(0,a.jsx)(n.li,{children:"Optimize scenes for AI perception tasks with appropriate lighting and textures"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["In the ",(0,a.jsx)(n.a,{href:"./02-isaac-ros-perception-navigation",children:"next chapter"}),", we'll explore how to connect these simulated sensors to Isaac ROS for perception and navigation processing."]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453(e,n,i){i.d(n,{R:()=>o,x:()=>s});var t=i(6540);const a={},r=t.createContext(a);function o(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);